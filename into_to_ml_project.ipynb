{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Best Model for Plan Recommendation #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: ##\n",
    "Our goal of finding a model that recommends the best plan to subscribers means investigating different types of Machine Learning algorithms. Need to build a binary-classification model that can predict the best mobile plan a user is likely to choose. Input features include 'calls', 'minutes', 'messages' and 'mb_used'. The aim of the model is to accurately categorise the sets into one of the two plans with an accuracy of 75% or higher on  unseen data. We'll be testing it against a decision tree model, a random forest model and a logistic regression model.\n",
    "\n",
    "The work plan will be implemented as follows: \n",
    "- Data Overview \n",
    "- EDA (determining if missing/duplicate values are present, checking datatypes and class imbalance)\n",
    "- Preprocessing (splitting data, rectifying possible imbalance)\n",
    "- Model training and testing \n",
    "- Final conclusions and best steps for Megaline going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary libraries \n",
    "import pandas as pd \n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a main dataframe to store info\n",
    "df_megaline = pd.read_csv('/Users/micha/Downloads/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the dataframe \n",
    "df_megaline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#getting the general info\n",
    "df_megaline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#general description of data\n",
    "df_megaline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 985 entries, 3 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     985 non-null    float64\n",
      " 1   minutes   985 non-null    float64\n",
      " 2   messages  985 non-null    float64\n",
      " 3   mb_used   985 non-null    float64\n",
      " 4   is_ultra  985 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 46.2 KB\n"
     ]
    }
   ],
   "source": [
    "#finding the amount of 'ultra' plan users\n",
    "df_megaline[df_megaline['is_ultra'] == 1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.647168637212197"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ultra plan users % \n",
    "(985 / 3214) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2229 entries, 0 to 3212\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     2229 non-null   float64\n",
      " 1   minutes   2229 non-null   float64\n",
      " 2   messages  2229 non-null   float64\n",
      " 3   mb_used   2229 non-null   float64\n",
      " 4   is_ultra  2229 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 104.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_megaline[df_megaline['is_ultra'] == 0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.35283136278781"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#smart plan users %\n",
    "(2229 / 3214) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating features and target variables for model development\n",
    "features = df_megaline.drop(['is_ultra'], axis=1)\n",
    "target = df_megaline['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training, validation and testing sets\n",
    "features_temp, features_test, target_temp, target_test = train_test_split(features, target, test_size=0.2, random_state=246, stratify=target)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_temp, target_temp, test_size=0.25, random_state=246, stratify=target_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES ON DATA SPLIT: ###\n",
    "The dataset was very imbalnced with only around 30% of all customers being enrolled in the 'Ultra' plan offered by Megline. To preserve class distribution across splits, stratified sampling was used. Especially important for imbalanced classification problems to ensure reliable model evaluation. \n",
    "\n",
    "**This code splits the data into:** \n",
    "- 'features_train', 'target_train' = 60% of the data\n",
    "- 'features_valid', 'target_valid' = 20% of the data\n",
    "- 'features_test', 'target_test' = 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set features shape: (1928, 4)\n",
      "Training set target shape: (1928,)\n",
      "Validation set features shape: (643, 4)\n",
      "Validation set target shape: (643,)\n",
      "Test set features shape: (643, 4)\n",
      "Test set features shape: (643,)\n"
     ]
    }
   ],
   "source": [
    "#printing the shape of each dataframe and getting the size\n",
    "print(f\"Training set features shape: {features_train.shape}\")\n",
    "print(f\"Training set target shape: {target_train.shape}\")\n",
    "print(f\"Validation set features shape: {features_valid.shape}\")\n",
    "print(f\"Validation set target shape: {target_valid.shape}\")\n",
    "print(f\"Test set features shape: {features_test.shape}\")\n",
    "print(f\"Test set features shape: {target_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training: ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created a custom function for model evaluation\n",
    "def evaluate_model(model, features_train, target_train, features_valid, target_valid, features_test, target_test):\n",
    "    \n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    preds = {\n",
    "        'train': model.predict(features_train),\n",
    "        'valid': model.predict(features_valid),\n",
    "        'test': model.predict(features_test)\n",
    "    }\n",
    "    probs = {\n",
    "        'train': model.predict_proba(features_train)[:, 1],\n",
    "        'valid': model.predict_proba(features_valid)[:, 1],\n",
    "        'test': model.predict_proba(features_test)[:, 1]\n",
    "    }\n",
    "    \n",
    "    metrics = {}\n",
    "    for split, y_true in zip(['train', 'valid', 'test'], [target_train, target_valid, target_test]):\n",
    "        y_preds = preds[split]\n",
    "        y_probs = probs[split]\n",
    "\n",
    "        metrics[split] = {\n",
    "            'accuracy': accuracy_score(y_true, y_preds),\n",
    "            'f1': f1_score(y_true, y_preds),\n",
    "            'roc_auc': roc_auc_score(y_true, y_probs)\n",
    "        }\n",
    "    results = {\n",
    "        'predictions': preds,\n",
    "        'probabilities': probs,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model: ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics: {'accuracy': 0.8449170124481328, 'f1': 0.7397737162750218, 'roc_auc': 0.878135887730062} \n",
      "Valid Metrics: {'accuracy': 0.7573872472783826, 'f1': 0.5894736842105263, 'roc_auc': 0.7257972729962896} \n",
      "Test Metrics: {'accuracy': 0.7589424572317263, 'f1': 0.5888594164456233, 'roc_auc': 0.7383908857071317}\n"
     ]
    }
   ],
   "source": [
    "#training a decision tree model and testing depth for best accuracy using the training and validation set\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=8,\n",
    "    random_state=246,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "results = evaluate_model(\n",
    "    dt_model,\n",
    "    features_train, target_train,\n",
    "    features_valid, target_valid,\n",
    "    features_test, target_test\n",
    ")\n",
    "print(f'Train Metrics: {results['metrics']['train']} \\nValid Metrics: {results['metrics']['valid']} \\nTest Metrics: {results['metrics']['test']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model: ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics: {'accuracy': 0.8475103734439834, 'f1': 0.7267657992565055, 'roc_auc': 0.8651639463556438} \n",
      "Valid Metrics: {'accuracy': 0.7916018662519441, 'f1': 0.6235955056179775, 'roc_auc': 0.819705902437914} \n",
      "Test Metrics: {'accuracy': 0.8040435458786936, 'f1': 0.6460674157303371, 'roc_auc': 0.809104049532221}\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    class_weight='balanced',\n",
    "    random_state=246\n",
    ")\n",
    "results = evaluate_model(\n",
    "    rf_model,\n",
    "    features_train, target_train,\n",
    "    features_valid, target_valid,\n",
    "    features_test, target_test\n",
    ")\n",
    "print(f'Train Metrics: {results['metrics']['train']} \\nValid Metrics: {results['metrics']['valid']} \\nTest Metrics: {results['metrics']['test']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics: {'accuracy': 0.6488589211618258, 'f1': 0.5208775654635527, 'roc_auc': 0.6757356356314551} \n",
      "Valid Metrics: {'accuracy': 0.6283048211508554, 'f1': 0.5031185031185031, 'roc_auc': 0.6666135530718627} \n",
      "Test Metrics: {'accuracy': 0.614307931570762, 'f1': 0.4723404255319149, 'roc_auc': 0.6414946165577837}\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(random_state=246, solver='liblinear', class_weight='balanced')\n",
    "results = evaluate_model(\n",
    "    log_reg_model, \n",
    "    features_train, target_train, \n",
    "    features_valid, target_valid,\n",
    "    features_test, target_test\n",
    ")\n",
    "print(f'Train Metrics: {results['metrics']['train']} \\nValid Metrics: {results['metrics']['valid']} \\nTest Metrics: {results['metrics']['test']}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Accuracy (validation): 0.6936236391912908\n"
     ]
    }
   ],
   "source": [
    "#testing against a dummy classifier \n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy_predictions = dummy.predict(features_valid)\n",
    "dummy_accuracy = accuracy_score(target_valid, dummy_predictions)\n",
    "print(f\"Dummy Accuracy (validation): {dummy_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model Training Conclusions: ###\n",
    "\n",
    "After training and testing on various model we can draw a few conclusions: \n",
    "- Evidence of overfitting on all models (except LogisticRegression) ***f1 score drops by around 10 between training, validation, test sets, more marginal drop in accuracy***\n",
    "- The DecisionTree/RandomForest performed better than company's accuracy threshold of 75%.\n",
    "- RandomForest was the most well rounded classifier of the 3 models tested with a final test accuarcy around 80% (very accurate),a final ROC-AUC of 0.8 (this means the model does a good job at valueing positive instances i.e. when a customer is a member of the 'Ultra' plan over negative instances. Better for prediction) and a final f1 of around 0.64 (meaning it does relatively well at catching positive results and avoiding false alarms, important in imbalanced dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier Conclusions: ###\n",
    "The results of the dummy classifer are what may be expected given the use of \"strategy='most_frequent'\" which returns only the most frequent class of whatever it we are testing for (here it's the smart user plan). Making it test at an accuracy around 70% our Decision Tree and Random Forest models both outperform the Dummy classifier by nearly 10% and even the Logical Regression model outperforms it when ran against the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Conclusion: #\n",
    "In the final analysis and for what Megaline hopes to achieve I would most recommend the RandomForestModel, it performed the best overall between all 3 metrics particulary on accuracy (achieved a score >= 0.75 as per company requests) and ROC-AUC which works hand in hand with accuracy and evaluating how the model values positive instances over negative ones (i.e. whether a user will be more compatible with the 'Ultra' or 'Smart' plan). Overall of the models that were evaluated it is the best performing, easy to use and will help the company in making the best recommendations to potential customers, meaning it can make the company much more profitable overall. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
